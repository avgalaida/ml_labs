{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def ds_df(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    for l in data:\n",
    "        inputs.append(l['input'].replace('\\n', ' '))\n",
    "        outputs.append(l['output'].replace('\\n', ' '))\n",
    "\n",
    "    df = pd.DataFrame({'i': inputs, 'o': outputs})\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60cb6af63fee95c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = ds_df('dataset.jsonl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8dfa8b6de4e8127",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.i[4] + '\\n')\n",
    "print(df.o[4])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25084a2c68ccd774",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "DEVICE = torch.device(\"mps\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa57852e3ab783f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"sberbank-ai/rugpt3medium_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7fdd23b13051860",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "SPECIAL_TOKENS = {'bos_token':'<bos>','eos_token' :'<eos>', 'pad_token':'<pad>', 'sep_token': '<sep>'}\n",
    "tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a6d5015b5eba58",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class DS(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_length=150):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        for idx in data.index.to_list():\n",
    "            inp = data.i[idx]\n",
    "            out = data.o[idx] \n",
    "\n",
    "            encodings_dict = tokenizer('<bos>'+ inp + '<sep>' + out + '<eos>',\n",
    "                                       truncation=True,\n",
    "                                       max_length=max_length,\n",
    "                                       padding=\"max_length\")\n",
    "\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "            \n",
    "            # if idx == 10000:\n",
    "            #     break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attn_masks': self.attn_masks[idx]\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc082299b0272145",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = DS(df, tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b435cf3572cba34",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15d67eb9c911d2d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dir = './'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38fed5840456efd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f'{dir}Checkouts', \n",
    "    overwrite_output_dir = True, \n",
    "    num_train_epochs = 8,\n",
    "    per_device_train_batch_size = 3,\n",
    "    per_device_eval_batch_size = 3,  \n",
    "    warmup_steps = 100,\n",
    "    gradient_accumulation_steps = 1, \n",
    "    save_steps = 3000\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2490d1638fb2173",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3638c5c32520ff1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.save_model(f'{dir}model_with_summary')\n",
    "tokenizer.save_vocabulary(f'{dir}tokenizer')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "babfa6d935cef6e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(f'{dir}tokenizer')\n",
    "model = GPT2LMHeadModel.from_pretrained(f'{dir}model_with_summary').to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb8d6b3d09a3be0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "SPECIAL_TOKENS = {'bos_token':'<bos>','eos_token' :'<eos>', 'pad_token':'<pad>', 'sep_token': '<sep>'}\n",
    "tokenizer.add_special_tokens(SPECIAL_TOKENS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91c8c0fe0f84d0b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class KeywordsStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, keywords_ids:list):\n",
    "        self.keywords = keywords_ids\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        if input_ids[0][-1] in self.keywords:\n",
    "            print(input_ids)\n",
    "            return True\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87de20fdbdc61b4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "stop_criteria = KeywordsStoppingCriteria(tokenizer.encode(tokenizer.eos_token, return_tensors=\"pt\").to(DEVICE))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6474692b558f455a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "inp = 'Продолжи диалог: Собеседник: Привет, чем ты сегодня занимался? Ты: <sep> '"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da60ad0de3b65d33",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "input_ids = tokenizer.encode(inp, return_tensors=\"pt\").to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb27f48a34c32d22",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids,\n",
    "                         do_sample=True,\n",
    "                         num_beams=3,\n",
    "                         temperature=2.0,\n",
    "                         top_p=0.9,\n",
    "                         max_length = 100,\n",
    "                         stopping_criteria=StoppingCriteriaList([stop_criteria]),\n",
    "                         eos_token_id=tokenizer.eos_token_id,\n",
    "                         bos_token_id=tokenizer.bos_token_id,\n",
    "                         ).to(DEVICE)\n",
    "print(tokenizer.batch_decode(out, skip_special_tokens=False)[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6283a651f337c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "s = tokenizer.batch_decode(out, skip_special_tokens=False)[0]\n",
    "s = s[len(inp):]\n",
    "\n",
    "i = s.find(\"Собеседник:\")\n",
    "if i != -1:\n",
    "    s = s[:i]\n",
    "\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbab1b292bbb7ac9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "def chat(promt):\n",
    "    while True:\n",
    "        print('-' * 80)\n",
    "        dialog = []\n",
    "        msg = '...'\n",
    "        while True:\n",
    "            msg = input('Сообщение:').strip()\n",
    "            if len(msg) == 0 or msg == 'й':\n",
    "                break\n",
    "            msg = msg[0].upper() + msg[1:]\n",
    "            dialog.append('Собеседник: ' + msg)\n",
    "            inp = f'{promt} Продолжи диалог:' + ''.join(dialog) + 'Ты: <sep>'\n",
    "\n",
    "            input_ids = tokenizer.encode(inp, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model.generate(input_ids,\n",
    "                                     do_sample=True,\n",
    "                                     num_beams=3,\n",
    "                                     temperature=2.0,\n",
    "                                     top_p=0.9,\n",
    "                                     max_length = 400,\n",
    "                                     stopping_criteria=StoppingCriteriaList([stop_criteria]),\n",
    "                                     eos_token_id=tokenizer.eos_token_id,\n",
    "                                     bos_token_id=tokenizer.bos_token_id,\n",
    "                                     ).to(DEVICE)\n",
    "\n",
    "\n",
    "            s = tokenizer.batch_decode(out, skip_special_tokens=False)[0]\n",
    "            s = s[len(inp):]\n",
    "            \n",
    "            i = s.find(\"Собеседник:\")\n",
    "            if i != -1:\n",
    "                s = s[:i]\n",
    "                \n",
    "            print(msg)\n",
    "            print('Бот:> {}'.format(s))\n",
    "            dialog.append('Ты: ' + s)\n",
    "            time.sleep(2)\n",
    "    \n",
    "        if msg == 'й':\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38d1a5a8f8e0fb76",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "chat('')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7a8757b089b16b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e566d4cc4d91915",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eedaebd4ce42d69d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
